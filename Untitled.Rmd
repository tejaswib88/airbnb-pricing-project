---
title: "tree_modelling"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(randomForest)
library(keras)
library(gbm)
```

```{r}
listings = read.csv("data/clean/cleaned_listings.csv")
listings = listings %>% mutate_if(is.character,as.factor)

set.seed(1)
#Generate training samples & split
train_samples = sample(1:nrow(listings), 0.8*nrow(listings))

train_samples
listings_train = listings %>% filter(row_number() %in% train_samples)
listings_train
listings_test = listings %>% filter(!(row_number() %in% train_samples))
```
```{r}
lm_fit = lm(price ~ ., data = listings_train)
summary = as_ibble(summary(lm_fit)$coefficients)
write_csv(x = summary, file = "results/linear-model-summary.csv")
```

```{r}
y_pred = predict(lm_fit, newdata = listings_test)
sqrt(mean((y_pred - listings_test$price)^2))
```

```{r}
dt_fit = rpart()
```


```{r}
rf_fit = randomForest(price ~ ., data = listings_train, importance = TRUE)

varImpPlot(rf_fit)
```

```{r}
plot(rf_fit)
```
```{r}
# might want to cache this chunk!
mvalues = seq(1,30, by = 2)
oob_errors = numeric(length(mvalues))
ntree = 500
for(idx in 1:length(mvalues)){
  m = mvalues[idx]
  rf_fit = randomForest(price ~ ., mtry = m, data = listings_train)
  oob_errors[idx] = rf_fit$mse[ntree]
}
tibble(m = mvalues, oob_err = oob_errors) %>%
  ggplot(aes(x = m, y = oob_err)) + 
  geom_line() + geom_point() + 
  scale_x_continuous(breaks = mvalues) +
  theme_bw()
```

```{r}
rf_finalfit = randomForest(price ~ ., mtry = 15, data = listings_train, 
                           importance = TRUE)
save(rf_finalfit, file = "models/rf_finalfit.Rda")
```

```{r}
rf_predictions = predict(rf_finalfit, newdata = listings_test)
rf_predictions
```
```{r}
listings_train
```
```{r}
listings_test
```

```{r}
sqrt(mean((rf_predictions - listings_test$price)^2))
```

```{r}
varImpPlot(rf_finalfit)
```
```{r}

```

```{r}
colnames(listings_test)
```
```{r}
colnames(listings_train)
```











